import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb


"""
========================================
ğŸš€ Aè‚¡å¤§ç¯å¢ƒæ‹©æ—¶ç³»ç»Ÿï¼ˆç¤ºä¾‹ç‰ˆï¼‰
========================================
åŠŸèƒ½è¯´æ˜ï¼š
1. ä½¿ç”¨å¤šä¸ªå®è§‚ + æƒ…ç»ªå› å­ï¼ˆåŒ—å‘èµ„é‡‘ã€æ¶¨åœå®¶æ•°ã€PEåˆ†ä½ã€æˆäº¤é‡ã€æ±‡ç‡ã€æ”¿ç­–å› å­ç­‰ï¼‰
2. å»ºç«‹ä¸¤ä¸ªæ¨¡å‹ï¼šé€»è¾‘å›å½’ + XGBoostï¼Œç”¨äºé¢„æµ‹â€œç¬¬äºŒå¤©æŒ‡æ•°æ¶¨è·Œæ¦‚ç‡â€
3. å°†æ¨¡å‹æ¦‚ç‡ + å› å­æ‰“åˆ†èåˆï¼Œç»™å‡º Aè‚¡â€œå¤§ç¯å¢ƒç­‰çº§â€ + ä¹°å–å»ºè®®

âš ï¸ é‡è¦è¯´æ˜ï¼š
- æœ¬è„šæœ¬ç›®å‰ç”¨â€œæ¨¡æ‹Ÿæ•°æ®â€æ¼”ç¤ºæµç¨‹ï¼Œæ–¹ä¾¿ä½ å…ˆè·‘é€šé€»è¾‘ï¼›
- å®ç›˜æ—¶ï¼Œä½ åªéœ€è¦æŠŠ `generate_mock_data()` æ¢æˆè¯»å–çœŸå®æ•°æ®ï¼ˆExcel/CSV/Tushareç­‰ï¼‰ï¼Œå³å¯æ— ç¼è¿ç§»ã€‚
"""


# ======================
# 1ï¸âƒ£ æ•°æ®å‡†å¤‡ï¼ˆè¿™é‡Œå…ˆç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
# ======================

def generate_mock_data(n_samples: int = 250) -> pd.DataFrame:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿå› å­ + æ ‡ç­¾æ•°æ®ã€‚
    çœŸå®ä½¿ç”¨æ—¶ï¼Œè¯·æ”¹å†™ä¸ºï¼šä»æœ¬åœ°æ–‡ä»¶ / Tushare / AkShare è¯»å–ä½ çš„å†å²æ•°æ®ã€‚
    """
    np.random.seed(42)

    data = {
        "åŒ—å‘èµ„é‡‘": np.random.uniform(-80, 250, n_samples),      # äº¿å…ƒ
        "æ¶¨åœå®¶æ•°": np.random.randint(5, 120, n_samples),        # åª
        "PEåˆ†ä½": np.random.uniform(0, 100, n_samples),          # %
        "æˆäº¤é‡": np.random.uniform(0.5, 2.5, n_samples),        # ä¸‡äº¿
        "æ±‡ç‡": np.random.uniform(6.8, 7.4, n_samples),          # USD/CNY
        "æ”¿ç­–å› å­": np.random.uniform(0, 10, n_samples),         # æ”¿ç­–æ”¯æŒåŠ›åº¦ 0-10
    }

    # ç®€å•è§„åˆ™ç”Ÿæˆâ€œç¬¬äºŒå¤©æ¶¨è·Œæ ‡ç­¾â€ï¼š1=æ¶¨ï¼Œ0=è·Œï¼ˆåªæ˜¯ç¤ºä¾‹ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ï¼‰
    labels = np.where(
        (data["åŒ—å‘èµ„é‡‘"] > 80)
        & (data["æ¶¨åœå®¶æ•°"] > 40)
        & (data["æˆäº¤é‡"] > 1.2)
        & (data["æ”¿ç­–å› å­"] > 6),
        1,
        0,
    )

    df = pd.DataFrame(data)
    df["æ ‡ç­¾"] = labels
    return df


# ======================
# 2ï¸âƒ£ å»ºç«‹å¤§ç¯å¢ƒâ€œå› å­æ‰“åˆ†ç³»ç»Ÿâ€
# ======================

def calc_environment_score(row: pd.Series) -> float:
    """
    æ ¹æ®å•æ—¥å› å­ï¼Œè®¡ç®—ä¸€ä¸ªâ€œå¤§ç¯å¢ƒç»¼åˆå¾—åˆ†â€ï¼ˆä»…ç¤ºä¾‹ï¼Œå¯æŒ‰ä½ è‡ªå·±çš„é€»è¾‘æ”¹ï¼‰ã€‚
    åˆ†å€¼å¤§è‡´åŒºé—´ï¼š-5 ~ +5ï¼Œè¶Šé«˜ä»£è¡¨ç¯å¢ƒè¶Šå¥½ã€‚
    """
    score = 0.0

    # åŒ—å‘èµ„é‡‘ï¼šå¤§å¹…æµå…¥åŠ åˆ†ï¼Œæµå‡ºå‡åˆ†
    if row["åŒ—å‘èµ„é‡‘"] > 100:
        score += 1.5
    elif row["åŒ—å‘èµ„é‡‘"] < 0:
        score -= 1.0

    # æ¶¨åœå®¶æ•°ï¼šè¶Šå¤šè¶Šä»£è¡¨æƒ…ç»ªå¥½
    if row["æ¶¨åœå®¶æ•°"] > 60:
        score += 1.0
    elif row["æ¶¨åœå®¶æ•°"] < 20:
        score -= 0.7

    # PEåˆ†ä½ï¼šå¤ªè´µå‡åˆ†ï¼Œä½ä¼°é€‚åº¦åŠ åˆ†
    if row["PEåˆ†ä½"] > 80:
        score -= 1.0
    elif row["PEåˆ†ä½"] < 30:
        score += 0.8

    # æˆäº¤é‡ï¼šæä½ä»£è¡¨æ²¡é‡ï¼Œæé«˜æœ‰æ—¶å¯èƒ½æ˜¯æƒ…ç»ªæç«¯
    if row["æˆäº¤é‡"] > 2.0:
        score += 0.5
    elif row["æˆäº¤é‡"] < 0.8:
        score -= 0.5

    # æ±‡ç‡ï¼šäººæ°‘å¸è´¬å€¼ï¼ˆæ±‡ç‡å‡é«˜ï¼‰ä¸€èˆ¬å¯¹è‚¡å¸‚ç•¥åç©º
    if row["æ±‡ç‡"] > 7.2:
        score -= 0.5
    elif row["æ±‡ç‡"] < 6.9:
        score += 0.3

    # æ”¿ç­–å› å­ï¼šé«˜åˆ†æ„å‘³ç€æ”¿ç­–åæš–
    if row["æ”¿ç­–å› å­"] > 7:
        score += 1.2
    elif row["æ”¿ç­–å› å­"] < 3:
        score -= 0.8

    return score


def map_env_level(env_score: float, prob_up: float) -> str:
    """
    å°†â€œå› å­å¾—åˆ† + ä¸Šæ¶¨æ¦‚ç‡â€æ˜ å°„ä¸ºå¤§ç¯å¢ƒç­‰çº§ã€‚
    å¯æ ¹æ®ä½ è‡ªå·±çš„é£é™©åå¥½è°ƒæ•´é˜ˆå€¼ã€‚
    """
    # ç®€å•èåˆï¼šç¯å¢ƒç»¼åˆè¯„åˆ† + æ¦‚ç‡åç¦» 0.5 çš„ç¨‹åº¦
    fused = env_score + (prob_up - 0.5) * 4  # æ¦‚ç‡æ”¾å¤§æƒé‡å¯è°ƒ

    if fused >= 3:
        return "æå¼ºå¤šå¤´ï¼ˆè¿›æ”»æœŸï¼‰"
    elif fused >= 1.5:
        return "å¼ºåŠ¿å¤šå¤´ï¼ˆæŒè‚¡ä¸ºä¸»ï¼‰"
    elif fused >= 0.5:
        return "æ¸©å’Œå¤šå¤´ï¼ˆé€‚åº¦å‚ä¸ï¼‰"
    elif fused >= -0.5:
        return "ä¸­æ€§éœ‡è¡ï¼ˆè°¨æ…ï¼Œæ§åˆ¶ä»“ä½ï¼‰"
    elif fused >= -2:
        return "åç©ºç¯å¢ƒï¼ˆé˜²å®ˆä¸ºä¸»ï¼‰"
    else:
        return "æå¼±ç¯å¢ƒï¼ˆç©ºä»“/åº•ä»“è§‚æœ›ï¼‰"


# ======================
# 3ï¸âƒ£ è®­ç»ƒæ¨¡å‹ï¼šé€»è¾‘å›å½’ + XGBoost
# ======================

def train_models(df: pd.DataFrame):
    feature_cols = ["åŒ—å‘èµ„é‡‘", "æ¶¨åœå®¶æ•°", "PEåˆ†ä½", "æˆäº¤é‡", "æ±‡ç‡", "æ”¿ç­–å› å­"]
    X = df[feature_cols]
    y = df["æ ‡ç­¾"]

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    # é€»è¾‘å›å½’
    lr = LogisticRegression(max_iter=1000)
    lr.fit(X_train, y_train)

    # XGBoost
    xgb_model = xgb.XGBClassifier(
        use_label_encoder=False,
        eval_metric="logloss",
        random_state=42,
    )
    xgb_model.fit(X_train, y_train)

    # åŸºæœ¬è¯„ä¼°
    y_pred_lr = lr.predict(X_test)
    y_prob_lr = lr.predict_proba(X_test)[:, 1]

    y_pred_xgb = xgb_model.predict(X_test)
    y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]

    print("\n=== é€»è¾‘å›å½’æ¨¡å‹è¯„ä¼° ===")
    print("å‡†ç¡®ç‡:", accuracy_score(y_test, y_pred_lr))
    print(classification_report(y_test, y_pred_lr))

    print("\n=== XGBoost æ¨¡å‹è¯„ä¼° ===")
    print("å‡†ç¡®ç‡:", accuracy_score(y_test, y_pred_xgb))
    print(classification_report(y_test, y_pred_xgb))

    return {
        "scaler": scaler,
        "lr": lr,
        "xgb": xgb_model,
        "feature_cols": feature_cols,
    }


# ======================
# 4ï¸âƒ£ ç”Ÿæˆâ€œå¤§ç¯å¢ƒæ‹©æ—¶ä¿¡å·â€
# ======================

def build_timing_signal(
    env_df: pd.DataFrame,
    models: dict,
    prob_threshold: float = 0.55,
) -> pd.DataFrame:
    """
    è¾“å…¥åŸå§‹å› å­æ•°æ® + è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¾“å‡ºæ¯ä¸€æ—¥ï¼š
    - æ¨¡å‹é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡ï¼ˆLR / XGB / èåˆï¼‰
    - å› å­ç¯å¢ƒå¾—åˆ†
    - å¤§ç¯å¢ƒç­‰çº§ & æ“ä½œå»ºè®®
    """
    feature_cols = models["feature_cols"]
    scaler = models["scaler"]
    lr = models["lr"]
    xgb_model = models["xgb"]

    X = env_df[feature_cols]
    X_scaled = scaler.transform(X)

    prob_lr = lr.predict_proba(X_scaled)[:, 1]
    prob_xgb = xgb_model.predict_proba(X_scaled)[:, 1]
    prob_ensemble = (prob_lr + prob_xgb) / 2

    # è®¡ç®—å› å­ç¯å¢ƒå¾—åˆ† & ç­‰çº§
    env_scores = env_df.apply(calc_environment_score, axis=1)
    env_levels = [
        map_env_level(score, p) for score, p in zip(env_scores, prob_ensemble)
    ]

    # æ ¹æ®æ¦‚ç‡å’Œç¯å¢ƒï¼Œç»™å‡ºç®€å•çš„ä»“ä½å»ºè®®ï¼ˆç¤ºä¾‹ï¼Œå¯è‡ªè°ƒï¼‰
    def decide_position(level: str, p: float) -> str:
        if "æå¼ºå¤šå¤´" in level:
            return "å»ºè®® ä»“ä½ 80%-100%"
        if "å¼ºåŠ¿å¤šå¤´" in level:
            return "å»ºè®® ä»“ä½ 60%-80%"
        if "æ¸©å’Œå¤šå¤´" in level:
            return "å»ºè®® ä»“ä½ 30%-60%"
        if "ä¸­æ€§éœ‡è¡" in level:
            return "å»ºè®® ä»“ä½ 10%-30%"
        if "åç©ºç¯å¢ƒ" in level:
            return "å»ºè®® ä»“ä½ 0%-20%ï¼Œä»¥é˜²å®ˆä¸ºä¸»"
        return "å»ºè®® ç©ºä»“æˆ–æä½ä»“ä½ï¼Œç­‰å¾…å³ä¾§ä¿¡å·"

    positions = [decide_position(lv, p) for lv, p in zip(env_levels, prob_ensemble)]

    result = env_df.copy()
    result["LR_ä¸Šæ¶¨æ¦‚ç‡"] = prob_lr
    result["XGB_ä¸Šæ¶¨æ¦‚ç‡"] = prob_xgb
    result["ç»¼åˆä¸Šæ¶¨æ¦‚ç‡"] = prob_ensemble
    result["å› å­ç¯å¢ƒå¾—åˆ†"] = env_scores
    result["å¤§ç¯å¢ƒç­‰çº§"] = env_levels
    result["ä»“ä½å»ºè®®"] = positions

    # å¯é€‰ï¼šç»™å‡ºä¸€ä¸ªç®€å•çš„â€œçœ‹å¤š/è§‚æœ›â€äºŒåˆ†ç±»ä¿¡å·ï¼ˆç”¨äºå›æµ‹ï¼‰
    result["å¤šç©ºä¿¡å·(1å¤š/0ç©º)"] = (prob_ensemble >= prob_threshold).astype(int)

    return result


def main():
    # 1. å‡†å¤‡æ•°æ®ï¼ˆè¿™é‡Œç”¨æ¨¡æ‹Ÿæ•°æ®ç¤ºä¾‹ï¼‰
    df = generate_mock_data(n_samples=250)

    # 2. è®­ç»ƒæ¨¡å‹
    models = train_models(df)

    # 3. ç”Ÿæˆå¤§ç¯å¢ƒæ‹©æ—¶ç»“æœ
    timing_df = build_timing_signal(df, models, prob_threshold=0.55)

    print("\n=== Aè‚¡å¤§ç¯å¢ƒæ‹©æ—¶ç»“æœï¼ˆæœ€è¿‘ 20 æ¡ï¼‰ ===")
    cols_to_show = [
        "åŒ—å‘èµ„é‡‘",
        "æ¶¨åœå®¶æ•°",
        "PEåˆ†ä½",
        "æˆäº¤é‡",
        "æ±‡ç‡",
        "æ”¿ç­–å› å­",
        "LR_ä¸Šæ¶¨æ¦‚ç‡",
        "XGB_ä¸Šæ¶¨æ¦‚ç‡",
        "ç»¼åˆä¸Šæ¶¨æ¦‚ç‡",
        "å› å­ç¯å¢ƒå¾—åˆ†",
        "å¤§ç¯å¢ƒç­‰çº§",
        "ä»“ä½å»ºè®®",
        "å¤šç©ºä¿¡å·(1å¤š/0ç©º)",
    ]
    print(timing_df[cols_to_show].tail(20))


if __name__ == "__main__":
    main()


